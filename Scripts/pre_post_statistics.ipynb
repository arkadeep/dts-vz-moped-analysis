{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "from config import DB_VISION_ZERO, DB_MOPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(query, cursor):\n",
    "    \"\"\"\n",
    "    Get data from database\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    data = cursor.fetchall()\n",
    "    field_names = [i[0] for i in cursor.description]\n",
    "    df = pd.DataFrame(data, columns=field_names)\n",
    "\n",
    "    return df\n",
    "\n",
    "conn_vz = psycopg2.connect(\n",
    "    dbname = DB_VISION_ZERO['dbname'],\n",
    "    user = DB_VISION_ZERO[\"user\"],\n",
    "    host = DB_VISION_ZERO[\"host\"],\n",
    "    password = DB_VISION_ZERO[\"password\"],\n",
    "    port=5432\n",
    ")\n",
    "\n",
    "conn_moped = psycopg2.connect(\n",
    "    dbname = DB_MOPED[\"dbname\"],\n",
    "    user = DB_MOPED[\"user\"],\n",
    "    host = DB_MOPED[\"host\"],\n",
    "    password = DB_MOPED[\"password\"],\n",
    "    port = 5432\n",
    ")\n",
    "\n",
    "cursor_vz = conn_vz.cursor()\n",
    "cursor_moped = conn_moped.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moped processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating moped dataframe\n",
    "QUERY_MOPED = \"\"\"SELECT project_id, project_component_id, geometry, \n",
    "line_geometry, substantial_completion_date,\n",
    "component_name, component_name_full, component_subtype, \n",
    "component_work_types, type_name FROM component_arcgis_online_view\"\"\"\n",
    "\n",
    "# Creating moped dataframe\n",
    "df_moped = get_data(QUERY_MOPED, cursor_moped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame info\n",
    "df_moped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping observations where substantial completion date or line geometry is absent\n",
    "df_moped_filter = df_moped.dropna(subset=['substantial_completion_date', 'line_geometry'])\n",
    "df_moped_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moped_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp columns to string\n",
    "timestamp_columns = [\"substantial_completion_date\"]\n",
    "\n",
    "for col in timestamp_columns:\n",
    "    df_moped_filter.loc[:, col] = df_moped_filter[col].astype(str)\n",
    "\n",
    "# Apply the geometry transformation\n",
    "df_moped_filter.loc[:, \"geometry\"] = df_moped_filter[\"geometry\"].apply(lambda x: shape(x) if x is not None else None)\n",
    "df_moped_filter.loc[:, \"line_geometry\"] = df_moped_filter[\"line_geometry\"].apply(lambda x: shape(x) if x is not None else None)\n",
    "\n",
    "# Create GeoDataFrame\n",
    "gdf_moped = gpd.GeoDataFrame(df_moped_filter, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a unique ID column\n",
    "gdf_moped.insert(0, 'moped_component_id', range(1, 1 + len(gdf_moped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_moped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VisionZero processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaing vision zero dataframe\n",
    "QUERY_CRASH_DATA = \"\"\"SELECT crash_id, crash_fatal_fl, crash_date,\n",
    "road_constr_zone_fl, latitude, longitude, tot_injry_cnt, \n",
    "death_cnt, est_comp_cost FROM atd_txdot_crashes\"\"\"\n",
    "\n",
    "df_vz = get_data(QUERY_CRASH_DATA, cursor_vz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keepiing only those observations where x-y coordinates are present\n",
    "df_vz_filter = df_vz[df_vz['latitude'].notnull() & df_vz['longitude'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vz_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp columns to string\n",
    "timestamp_columns = [\"crash_date\"]\n",
    "\n",
    "for col in timestamp_columns:\n",
    "    df_vz_filter.loc[:, col] = df_vz_filter[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating geodataframe\n",
    "gdf_vz = gpd.GeoDataFrame(df_vz_filter,\n",
    "                          geometry=gpd.points_from_xy(df_vz_filter.longitude,\n",
    "                                                      df_vz_filter.latitude),\n",
    "                                                      crs='EPSG:4326')\n",
    "\n",
    "gdf_vz.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating buffer for joining\n",
    "gdf_moped = gdf_moped.set_geometry('line_geometry')\n",
    "gdf_moped.set_crs(epsg=4326, inplace=True)\n",
    "gdf_moped_proj = gdf_moped.to_crs(epsg=32614)\n",
    "buffer_distance = 20\n",
    "\n",
    "gdf_moped_proj = gdf_moped.to_crs(epsg=32614)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_moped_proj['buffered_geometry'] = gdf_moped_proj.geometry.buffer(buffer_distance)\n",
    "buffered_moped_gdf = gdf_moped_proj.set_geometry('buffered_geometry').to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffered geometry results in line strings and multi line strings being turned into polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_moped_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join\n",
    "crashes_near_projects = gpd.sjoin(gdf_vz, buffered_moped_gdf, how='inner')\n",
    "\n",
    "# Creating a unique ID column\n",
    "crashes_near_projects['crash_project_component_id'] = crashes_near_projects['crash_id'].astype(str) + \"-\" + crashes_near_projects['project_id'].astype(str) + \"-\" + crashes_near_projects['project_component_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique crashes in merged dataset:', crashes_near_projects['crash_id'].nunique())\n",
    "print('Number of unique moped component IDs in merged dataset:', crashes_near_projects['moped_component_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_near_projects.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting crash date\n",
    "crashes_near_projects['crash_date'] = pd.to_datetime(crashes_near_projects['crash_date'], errors='coerce').dt.tz_localize('UTC', nonexistent='NaT', ambiguous='NaT').dt.tz_convert('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_near_projects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arranging columns\n",
    "# unique identifier for each observation\n",
    "crashes_near_projects.insert(0, 'crash_project_component_id', crashes_near_projects.pop('crash_project_component_id'))\n",
    "\n",
    "# moped_component_id\n",
    "crashes_near_projects.insert(2, 'moped_component_id', crashes_near_projects.pop('moped_component_id'))\n",
    "\n",
    "# crash_date\n",
    "crashes_near_projects.insert(4, 'crash_date', crashes_near_projects.pop('crash_date'))\n",
    "\n",
    "# project compoenent ID\n",
    "crashes_near_projects.insert(3, 'project_component_id', crashes_near_projects.pop('project_component_id'))\n",
    "\n",
    "# Substantial completion date\n",
    "crashes_near_projects.insert(5, 'substantial_completion_date', crashes_near_projects.pop('substantial_completion_date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a binary version of the fatality column\n",
    "crashes_near_projects['crash_fatal_binary'] = crashes_near_projects['crash_fatal_fl'].apply(lambda x: 1 if x == \"Y\" else 0)\n",
    "crashes_near_projects.pop('crash_fatal_fl')\n",
    "\n",
    "# Rearranging the crash fatal binary column \n",
    "crashes_near_projects.insert(4, 'crash_fatal_binary', crashes_near_projects.pop('crash_fatal_binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_near_projects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_near_projects['crash_fatal_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crashes_near_projects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating indicator variables for crash occuring pre and post completion of mobility project\n",
    "crashes_near_projects.insert(7, 'crash_pre_completion', crashes_near_projects['crash_date'] < crashes_near_projects['substantial_completion_date'])\n",
    "crashes_near_projects.insert(8, 'crash_post_completion', crashes_near_projects['crash_date'] > crashes_near_projects['substantial_completion_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating time difference variables\n",
    "crashes_near_projects.insert(9, 'crash_project_date_diff', crashes_near_projects['substantial_completion_date'] - crashes_near_projects['crash_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting estimated comp cost to float format\n",
    "crashes_near_projects['est_comp_cost'] = crashes_near_projects['est_comp_cost'].map(lambda x: float(x))\n",
    "\n",
    "crashes_near_projects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate duration in years\n",
    "def calculate_duration(df, date_col1, date_col2):\n",
    "    duration = (df[date_col2] - df[date_col1]).dt.total_seconds() / (365.25 * 24 * 3600)\n",
    "    return duration\n",
    "\n",
    "crashes_near_projects['pre_completion_duration'] = crashes_near_projects['crash_pre_completion'] * calculate_duration(crashes_near_projects, 'crash_date', 'substantial_completion_date')\n",
    "crashes_near_projects['post_completion_duration'] = crashes_near_projects['crash_post_completion'] * calculate_duration(crashes_near_projects, 'substantial_completion_date', 'crash_date')\n",
    "\n",
    "pre_completion_stats = crashes_near_projects[crashes_near_projects['crash_pre_completion'] == True].groupby('moped_component_id').agg({\n",
    "    'crash_id': 'count',\n",
    "    'pre_completion_duration': 'sum',\n",
    "    'crash_fatal_binary': 'sum',\n",
    "    'tot_injry_cnt': 'sum',\n",
    "    'death_cnt': 'sum',\n",
    "    'est_comp_cost': 'sum'\n",
    "}).rename(columns={'crash_id': 'pre_crash_count',\n",
    "                   'crash_fatal_binary': 'pre_fatal_crash_count',\n",
    "                   'tot_injry_cnt': 'pre_total_injury_count',\n",
    "                   'death_cnt': 'pre_total_death_count',\n",
    "                   'est_comp_cost': 'pre_est_comp_cost'}).reset_index()\n",
    "\n",
    "post_completion_stats = crashes_near_projects[crashes_near_projects['crash_post_completion'] == True].groupby('moped_component_id').agg({\n",
    "    'crash_id': 'count',\n",
    "    'post_completion_duration': 'sum',\n",
    "    'crash_fatal_binary': 'sum',\n",
    "    'tot_injry_cnt': 'sum',\n",
    "    'death_cnt': 'sum',\n",
    "    'est_comp_cost': 'sum'\n",
    "}).rename(columns={'crash_id': 'post_crash_count',\n",
    "                   'crash_fatal_binary': 'post_fatal_crash_count',\n",
    "                   'tot_injry_cnt': 'post_total_injury_count',\n",
    "                   'death_cnt': 'post_total_death_count',\n",
    "                   'est_comp_cost': 'post_est_comp_cost'}).reset_index()\n",
    "\n",
    "\n",
    "# Merging\n",
    "annualized_statistics = pre_completion_stats.merge(post_completion_stats, on='moped_component_id', how='outer').fillna(0)\n",
    "\n",
    "# Calculating annualized statistics\n",
    "# Crash rate\n",
    "annualized_statistics['pre_annualized_crash_rate'] = annualized_statistics['pre_crash_count'] / annualized_statistics['pre_completion_duration']\n",
    "annualized_statistics['post_annualized_crash_rate'] = annualized_statistics['post_crash_count'] / annualized_statistics['post_completion_duration']\n",
    "\n",
    "# Fatality\n",
    "annualized_statistics['pre_annualized_fatal_crash_rate'] = annualized_statistics['pre_fatal_crash_count'] / annualized_statistics['pre_completion_duration']\n",
    "annualized_statistics['post_annualized_fatal_crash_rate'] = annualized_statistics['post_fatal_crash_count'] / annualized_statistics['post_completion_duration']\n",
    "\n",
    "# Injury count\n",
    "annualized_statistics['pre_annualized_injury_rate'] = annualized_statistics['pre_total_injury_count'] / annualized_statistics['pre_completion_duration']\n",
    "annualized_statistics['post_annualized_injury_rate'] = annualized_statistics['post_total_injury_count'] / annualized_statistics['post_completion_duration']\n",
    "\n",
    "# Death count\n",
    "annualized_statistics['pre_annualized_death_rate'] = annualized_statistics['pre_total_death_count'] / annualized_statistics['pre_completion_duration']\n",
    "annualized_statistics['post_annualized_death_rate'] = annualized_statistics['post_total_death_count'] / annualized_statistics['post_completion_duration']\n",
    "\n",
    "# Estimated cost\n",
    "annualized_statistics['pre_annualized_cost'] = annualized_statistics['pre_est_comp_cost'] / annualized_statistics['pre_completion_duration']\n",
    "annualized_statistics['post_annualized_cost'] = annualized_statistics['post_est_comp_cost'] / annualized_statistics['post_completion_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting completion date for each moped component id\n",
    "completion_dates = crashes_near_projects.groupby('moped_component_id')['substantial_completion_date'].first().reset_index()\n",
    "\n",
    "# Merging into the annualized crash rate DataFrame\n",
    "annualized_statistics = annualized_statistics.merge(completion_dates, on='moped_component_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_statistics = annualized_statistics[['moped_component_id',\n",
    "                                               'substantial_completion_date', \n",
    "                                               'pre_annualized_crash_rate', \n",
    "                                               'post_annualized_crash_rate',\n",
    "                                               'pre_annualized_fatal_crash_rate',\n",
    "                                               'post_annualized_fatal_crash_rate',\n",
    "                                               'pre_annualized_injury_rate',\n",
    "                                               'post_annualized_injury_rate',\n",
    "                                               'pre_annualized_death_rate',\n",
    "                                               'post_annualized_death_rate',\n",
    "                                               'pre_annualized_cost',\n",
    "                                               'post_annualized_cost'\n",
    "                                               ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_statistics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating difference columns between pre and post\n",
    "annualized_statistics.insert(4, 'delta_crash_rate', annualized_statistics['post_annualized_crash_rate']  - annualized_statistics['pre_annualized_crash_rate'])\n",
    "annualized_statistics.insert(7, 'delta_fatal_crash_rate', annualized_statistics['post_annualized_fatal_crash_rate']  - annualized_statistics['pre_annualized_fatal_crash_rate'])\n",
    "annualized_statistics.insert(10, 'delta_injury_rate', annualized_statistics['post_annualized_injury_rate']  - annualized_statistics['pre_annualized_injury_rate'])\n",
    "annualized_statistics.insert(13, 'delta_death_rate', annualized_statistics['post_annualized_death_rate']  - annualized_statistics['pre_annualized_death_rate'])\n",
    "annualized_statistics.insert(16, 'delta_comp_cost', annualized_statistics['post_annualized_cost']  - annualized_statistics['pre_annualized_cost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging additional information such as component name, type, etc.\n",
    "additional_info = crashes_near_projects[['moped_component_id', \n",
    "                                         'component_name', \n",
    "                                         'component_name_full', \n",
    "                                         'component_subtype',\n",
    "                                         'component_work_types', \n",
    "                                         'type_name',\n",
    "                                         'line_geometry']].drop_duplicates()\n",
    "\n",
    "annualized_statistics = annualized_statistics.merge(additional_info, on='moped_component_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_statistics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering\n",
    "all_columns = annualized_statistics.columns.tolist()\n",
    "\n",
    "first_column = all_columns[0]\n",
    "last_six = all_columns[-6:]\n",
    "new_order = [first_column] + last_six + all_columns[1:-6]\n",
    "annualized_statistics = annualized_statistics[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualized_statistics.to_csv('../Output/annualized_statistics.csv', na_rep=\"NA\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
